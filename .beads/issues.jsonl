{"id":"popup-ai-05k","title":"STT pipeline via mlx whisper","description":"Integrate mlx-whisper for realtime transcription; configurable chunk length, overlap, VAD/silence thresholds, and partial vs final segment handling. Expose these settings in admin UI and persist to DB. Provide sensible defaults aligned with Whisper decode parameters (temperature schedule, no_speech_threshold, logprob_threshold, compression_ratio_threshold, condition_on_previous_text).","status":"open","priority":2,"issue_type":"feature","owner":"fcorrao@gmail.com","created_at":"2026-01-17T13:53:48.770471-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T15:37:45.528732-05:00","dependencies":[{"issue_id":"popup-ai-05k","depends_on_id":"popup-ai-xps","type":"blocks","created_at":"2026-01-17T13:55:18.312038-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-05k","depends_on_id":"popup-ai-0q4","type":"blocks","created_at":"2026-01-17T14:37:42.973001-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-05k","depends_on_id":"popup-ai-f33","type":"blocks","created_at":"2026-01-17T15:43:46.207273-05:00","created_by":"Frank Corrao"}],"comments":[{"id":4,"issue_id":"popup-ai-05k","author":"Frank Corrao","text":"TranscriberActor implemented in src/popup_ai/actors/transcriber.py:\n- Pulls AudioChunks from Ray Queue\n- Accumulates audio in buffer until chunk_length_s reached\n- Keeps overlap between chunks for continuity\n- Writes temp WAV file for mlx-whisper (workaround for PCM input)\n- Pushes Transcript to output queue with segments\n\nConfig exposed: model, chunk_length_s, overlap_s, language.\n\nMissing from spec:\n- VAD/silence thresholds\n- Partial vs final segment handling (currently all final)\n- Whisper decode parameters (temperature, thresholds)\n- UI controls for STT tuning\n- Settings persistence","created_at":"2026-01-17T23:03:46Z"}]}
{"id":"popup-ai-0q4","title":"Audio transport abstraction + Option C (OBS SRT ingest) spike","description":"Audio transport abstraction with Option C (OBS-\u003eSRT ingest) as v1 path; run LAN spike to measure E2E latency and STT throughput. Keep AudioSource interface pluggable for future WebRTC/direct capture. **Experiment checklist:** (1) Configure OBS SRT output to Mac listener (mode=caller, set latency 120-200ms); (2) Run ffmpeg listener -\u003e PCM 16k mono to stdout; (3) Verify audio format (sample rate/channels) and compute chunk sizes; (4) Measure end-to-end latency with clap/beep and timestamped logs (capture time, ffmpeg ingest time, STT output time); (5) Measure CPU/throughput on M3 Ultra; (6) Test reconnect behavior when OBS stream stops/starts; (7) Record measured latencies + recommended SRT/ffmpeg settings.","status":"open","priority":2,"issue_type":"feature","owner":"fcorrao@gmail.com","created_at":"2026-01-17T14:37:22.704496-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T15:26:04.919312-05:00","comments":[{"id":2,"issue_id":"popup-ai-0q4","author":"Frank Corrao","text":"AudioIngestActor implemented with ffmpeg SRT→PCM capture in src/popup_ai/actors/audio_ingest.py. Configurable SRT port, latency, sample rate, channels. Uses subprocess.Popen to spawn ffmpeg listening on SRT. Chunks pushed to Ray Queue. Still needs: latency measurement experiment, reconnect testing, CPU/throughput benchmarks on M3 Ultra.","created_at":"2026-01-17T23:02:56Z"}]}
{"id":"popup-ai-0rv","title":"Architecture \u0026 data flow doc for live pipeline","description":"Document end-to-end flow with v1 decisions: OBS-\u003eSRT ingest on LAN; base scene popup-base-scene with 4 slot scenes popup-scene-1..4 and text sources popup-scene-text1..4; update/show/hold 5s/hide; LLM single annotation; admin UI prompt + STT controls persisted to SQLite; 5s latency target; cache prompt+term results. Track spec doc in popup-ai-61r.","status":"open","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T13:53:18.118395-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T16:57:12.822501-05:00"}
{"id":"popup-ai-31e","title":"Multi-Language Translation","description":"Display annotations in multiple languages simultaneously or switch based on viewer preference. TranslationActor after Annotator calls translation API (DeepL, Google, or LLM). Display original in slot 1, translated in slot 2.","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:34:52.744674-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:34:52.744674-05:00","labels":["i18n","speculative"]}
{"id":"popup-ai-3nn","title":"Deep Dive Panel - Visual Research for Annotations","description":"**Overview**: Right panel browser source that displays rich content (images, code examples) for selected annotation topics. Complements the left chatlog panel.\n\n**Architecture**:\n- Left Panel: Chatlog of annotations (existing)\n- Right Panel: Deep dive content - images + code for AI-selected interesting terms\n\n**Components**:\n1. DeepDiveSelector - AI picks interesting/complex terms from recent annotations\n2. ResearcherActor - Async web search for images and code examples  \n3. overlay-deepdive.html - Right panel browser source display\n4. Broadcast routing by type (annotation vs deepdive)\n\n**User Choices**:\n- Topic Selection: Auto-select (AI picks most interesting term)\n- Content: Images + Code examples\n- Source: Web search (built-in API with rate limits)\n\n**Phased Implementation**:\n- Phase 1: Right panel infrastructure with mock data\n- Phase 2: ResearcherActor with web search API\n- Phase 3: Smart selection logic\n- Phase 4: Polish and fallbacks\n\n**URL Config**:\n- Left: overlay.html?mode=chatlog\n- Right: overlay-deepdive.html","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-20T23:23:39.838006-05:00","created_by":"Frank Corrao","updated_at":"2026-01-20T23:23:39.838006-05:00","labels":["browser-overlay","speculative"]}
{"id":"popup-ai-3tj","title":"End-to-end pipeline smoke test harness","description":"Local harness to validate audio-\u003eSTT-\u003eLLM-\u003eOBS control flow; can stub OBS or use local websocket.","status":"open","priority":3,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T13:54:27.447863-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T14:38:49.870139-05:00","dependencies":[{"issue_id":"popup-ai-3tj","depends_on_id":"popup-ai-3yz","type":"blocks","created_at":"2026-01-17T13:56:03.030475-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-3tj","depends_on_id":"popup-ai-w5n","type":"blocks","created_at":"2026-01-17T13:56:10.075333-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-3yz","title":"Remote audio ingest service","description":"Implement remote audio ingest service behind AudioSource interface; v1 adapter uses ffmpeg CLI to ingest OBS SRT (listener), decode audio to PCM, and stream frames into pipeline via subprocess stdout (no pexpect). Baseline defaults: SRT port 9000, latency 120-200ms (configurable), PCM s16le mono 16k. Support ingest-only + record-only modes (popup-ai-f33). Track ffmpeg baseline doc in popup-ai-4as.","status":"open","priority":2,"issue_type":"feature","owner":"fcorrao@gmail.com","created_at":"2026-01-17T13:53:33.747222-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T16:57:16.889901-05:00","dependencies":[{"issue_id":"popup-ai-3yz","depends_on_id":"popup-ai-xps","type":"blocks","created_at":"2026-01-17T13:55:00.513769-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-3yz","depends_on_id":"popup-ai-0q4","type":"blocks","created_at":"2026-01-17T14:37:40.378748-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-3yz","depends_on_id":"popup-ai-f33","type":"blocks","created_at":"2026-01-17T15:43:46.152037-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-41e","title":"Logging/metrics/trace for live pipeline","description":"Structured logging + basic metrics for latency, errors, OBS actions, STT throughput; wire into pipeline.","status":"open","priority":3,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T13:54:19.247633-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T14:38:49.814857-05:00","dependencies":[{"issue_id":"popup-ai-41e","depends_on_id":"popup-ai-xps","type":"blocks","created_at":"2026-01-17T13:55:55.368974-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-445","title":"API surface (FastAPI) for control + UI","description":"FastAPI endpoints for status, session control, and event streams to UI; integrate with service layer.","status":"open","priority":2,"issue_type":"feature","owner":"fcorrao@gmail.com","created_at":"2026-01-17T13:54:04.096766-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T14:38:49.595864-05:00","dependencies":[{"issue_id":"popup-ai-445","depends_on_id":"popup-ai-w5n","type":"blocks","created_at":"2026-01-17T13:55:41.090446-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-4as","title":"FFmpeg SRT ingest baseline + run modes","description":"Define ffmpeg CLI baseline for OBS-\u003eSRT ingest (port/latency/PCM format) and document modular run modes (ingest-only, record-only, transcribe-only, annotate-only, full pipeline).","status":"open","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T16:56:59.26916-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T16:56:59.26916-05:00","dependencies":[{"issue_id":"popup-ai-4as","depends_on_id":"popup-ai-3yz","type":"blocks","created_at":"2026-01-17T16:57:07.381329-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-4as","depends_on_id":"popup-ai-f33","type":"blocks","created_at":"2026-01-17T16:57:07.437267-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-4cs","title":"OBS control contract + scene collection template","description":"Define v1 OBS scene collection contract: base scene default name popup-base-scene (configurable). 4 overlay slot scenes named popup-scene-1..popup-scene-4 (anchored to corners). Each slot scene contains a text source named popup-scene-text1..4 (user styles freely) and any optional background elements. Base scene includes each slot scene as a Scene Source item (item names match scene names). Server updates text via SetInputSettings and toggles visibility by enabling/disabling the scene item for popup-scene-N in popup-base-scene. v1: update/show/hold/hide only (no transitions).","status":"open","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T14:44:16.448956-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T15:37:41.856799-05:00","comments":[{"id":8,"issue_id":"popup-ai-4cs","author":"Frank Corrao","text":"OBS setup documented in docs/tutorials/obs-setup.md. Specifies:\n- Scene: popup-ai-overlay (configurable via POPUP_OVERLAY_SCENE_NAME)\n- Text sources: popup-ai-slot-1 through popup-ai-slot-4\n- WebSocket: port 4455 (OBS 28+ built-in)\n- SRT: port 9998, mode=caller, latency=200000\n\nStill needed: actual OBS scene collection template file (.json) that users can import.","created_at":"2026-01-18T02:12:06Z"}]}
{"id":"popup-ai-4l4","title":"Code Snippet Detection \u0026 Formatting","description":"When speaker mentions code, detect and display formatted snippet. Annotator prompt detects code references, LLM generates minimal example, display in monospace OBS source with syntax highlighting via browser source.","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:35:13.969287-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:35:13.969287-05:00","labels":["intelligence","speculative"]}
{"id":"popup-ai-5kp","title":"Compositor: Admin UI Integration","description":"Admin UI settings panel for compositor configuration.\n\n**Location:** Admin UI (NiceGUI)\n\n**Settings Panel:**\n- Enable/disable compositor (vs OBS mode)\n- Video source selection (webcam dropdown, SRT URL input, screen region picker)\n- Resolution and FPS settings\n- NDI source name\n- Text styling (font, size, colors)\n- Preview window showing current output\n\n**Status Display:**\n- Compositor running/stopped indicator\n- Current FPS / dropped frames\n- NDI connection status\n- Video input status\n\n**Preview:**\n- Small live preview of composed output\n- Useful for positioning text slots\n- Toggle on/off to reduce CPU\n\n**Implementation Notes:**\n- Reuse existing NiceGUI patterns from admin UI\n- Config changes should apply without restart if possible\n- Store settings in same config system as other actors","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:56:33.299593-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:56:33.299593-05:00","labels":["compositor","speculative"]}
{"id":"popup-ai-5vw","title":"Vision-Aware Contextual Positioning","description":"Use screen capture + vision model to understand what's on screen and position annotations intelligently. VisionActor captures OBS output periodically, vision LLM analyzes frame, overlay uses SetSceneItemTransform to move slots dynamically.","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:34:52.551417-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:34:52.551417-05:00","labels":["speculative","vision"]}
{"id":"popup-ai-5y9","title":"Triggered Annotations (Keyword Detection)","description":"Only annotate when specific trigger phrases detected. Config: trigger_phrases list. Pre-filter in Transcriber or Annotator. Reduces noise, catches intentional explanations.","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:35:14.541854-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:35:14.541854-05:00","labels":["annotator","speculative"]}
{"id":"popup-ai-61r","title":"V1 spec one-pager","description":"Produce a concise v1 specification document (goals, defaults, non-goals, risks) capturing OBS-\u003eSRT ingest, scene contract, 4-slot overlay, 5s latency/hold, single annotation per term, admin UI controls, and caching.","status":"open","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T16:56:56.203251-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T16:56:56.203251-05:00","dependencies":[{"issue_id":"popup-ai-61r","depends_on_id":"popup-ai-0rv","type":"blocks","created_at":"2026-01-17T16:57:07.324873-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-6ai","title":"Compositor: Video Input Layer","description":"Abstraction layer for multiple video input sources.\n\n**File:** src/popup_ai/video_input.py\n\n**Supported Sources:**\n1. Webcam capture via OpenCV (cv2.VideoCapture)\n2. SRT/RTMP stream via PyAV decode\n3. Screen capture via mss library (optional)\n\n**Interface:**\n```python\nclass VideoInput(Protocol):\n    def get_frame(self) -\u003e np.ndarray | None: ...\n    def get_resolution(self) -\u003e tuple[int, int]: ...\n    def get_fps(self) -\u003e int: ...\n    def start(self) -\u003e None: ...\n    def stop(self) -\u003e None: ...\n```\n\n**Considerations:**\n- Async frame fetching to not block compositor\n- Frame format: BGR (OpenCV) or RGB, convert to BGRA for NDI\n- Handle camera disconnection gracefully\n- Support resolution/fps configuration\n\n**Dependencies:** opencv-python, av (PyAV), mss","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:56:31.912121-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:56:31.912121-05:00","labels":["compositor","speculative"]}
{"id":"popup-ai-6up","title":"System Diagnostics Actor \u0026 UI","description":"Add optional diagnostics actor using psutil to capture system stats (CPU, memory, disk I/O, network). UI tab shows live graphs and can export logs for debugging unresponsive box issues during streaming.","status":"open","priority":3,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T21:37:29.306685-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T21:37:29.306685-05:00","labels":["diagnostics","optional","ui"]}
{"id":"popup-ai-6up.1","title":"DiagnosticsActor with psutil sampling","description":"Create DiagnosticsActor that samples psutil stats every second: cpu_percent, memory, disk_io_counters, net_io_counters. Store in ring buffer. Publish to UI queue.","status":"open","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T21:37:38.277796-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T21:37:38.277796-05:00","labels":["diagnostics"],"dependencies":[{"issue_id":"popup-ai-6up.1","depends_on_id":"popup-ai-6up","type":"parent-child","created_at":"2026-01-19T21:37:38.278487-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-6up.2","title":"Diagnostics UI tab with live charts","description":"Add Diagnostics tab to UI with live updating charts for CPU, memory, disk I/O, network. Use NiceGUI chart component. Highlight anomalies/spikes.","status":"open","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T21:37:38.345478-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T21:37:38.345478-05:00","labels":["diagnostics","ui"],"dependencies":[{"issue_id":"popup-ai-6up.2","depends_on_id":"popup-ai-6up","type":"parent-child","created_at":"2026-01-19T21:37:38.346143-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-6up.3","title":"Diagnostics log export","description":"Add export button to download diagnostics history as JSON/CSV for offline analysis.","status":"open","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T21:37:38.413274-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T21:37:38.413274-05:00","labels":["diagnostics","ui"],"dependencies":[{"issue_id":"popup-ai-6up.3","depends_on_id":"popup-ai-6up","type":"parent-child","created_at":"2026-01-19T21:37:38.413925-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-71i","title":"Compositor: Audio Pass-through","description":"Route audio to both transcription pipeline and output stream.\n\n**Current Audio Flow:**\nSRT → FFmpeg → PCM chunks → TranscriberActor\n\n**New Audio Flow with Compositor:**\n```\n                    ┌──► TranscriberActor (transcription)\nSRT Audio ──► FFmpeg ──┤\n                    └──► NDI Audio out (for recording/streaming)\n```\n\n**Implementation Options:**\n\n1. **NDI Audio Interleaved:**\n   - ndi-python supports audio frames\n   - Send audio interleaved with video\n   - Requires audio/video sync timestamps\n\n2. **Separate Audio Stream:**\n   - Keep audio in FFmpeg subprocess\n   - Output to SRT or separate NDI source\n   - Simpler but less integrated\n\n3. **PyAV Audio Handling:**\n   - Decode audio alongside video in PyAV\n   - Forward to both transcription and NDI\n\n**Sync Considerations:**\n- Audio and video must stay in sync\n- Buffer management to handle processing latency\n- PTS timestamps from source should be preserved\n\n**Priority:** Medium - can ship MVP without audio in compositor output","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:56:33.566486-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:56:33.566486-05:00","labels":["compositor","speculative"]}
{"id":"popup-ai-7ur","title":"Compositor: Text Rendering Engine","description":"Text overlay compositing on video frames.\n\n**Reuse Logic From:** src/popup_ai/actors/overlay.py (slot management, scroll calculation)\n\n**Implementation:**\n- PIL/Pillow for text rendering with custom fonts\n- Multiple text slots with configurable positions\n- Scrolling text via frame-by-frame X position updates\n- Background boxes/shadows for readability\n\n**Slot System (same as current OBS integration):**\n- Slots: popup-ai-slot-1, slot-2, slot-3, etc.\n- First available slot selection\n- Queue when all slots busy\n- Auto-hide after display_duration_ms\n\n**Scroll Calculation:**\n```python\n# From current overlay.py - reuse this logic\ntotal_travel = text_width + viewport_width\nspeed = total_travel / duration_s\n# Update X position each frame: x -= speed / fps\n```\n\n**Frame Compositing:**\n1. Get base frame from video input\n2. For each active slot, render text at current position\n3. Alpha-blend text onto frame\n4. Output composed frame to NDI\n\n**Dependencies:** Pillow, numpy","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:56:32.464354-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:56:32.464354-05:00","labels":["compositor","speculative"]}
{"id":"popup-ai-8iq","title":"OBS websocket client + overlay control tool","description":"OBS websocket client for scenes/sources; implement update (SetInputSettings), show/hide (SetSceneItemEnabled on slot scene items). Uses standard slot names popup-scene-1..4 and text sources popup-scene-text1..4; config mapping allows overrides. Transition hooks pluggable later.","status":"open","priority":2,"issue_type":"feature","owner":"fcorrao@gmail.com","created_at":"2026-01-17T13:53:41.319943-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T15:19:58.215674-05:00","dependencies":[{"issue_id":"popup-ai-8iq","depends_on_id":"popup-ai-xps","type":"blocks","created_at":"2026-01-17T13:55:07.802982-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-8iq","depends_on_id":"popup-ai-4cs","type":"blocks","created_at":"2026-01-17T14:44:24.524583-05:00","created_by":"Frank Corrao"}],"comments":[{"id":6,"issue_id":"popup-ai-8iq","author":"Frank Corrao","text":"OverlayActor implemented in src/popup_ai/actors/overlay.py:\n- Uses obsws-python ReqClient for OBS WebSocket v5\n- Pulls Annotations from Ray Queue\n- Manages 4 overlay slots with auto-hide after display_duration_ms\n- Creates text sources (popup-ai-slot-1..4) on init if missing\n- Updates text via set_input_settings\n- Cleanup loop clears expired slots\n\nConfig: obs_host, obs_port, obs_password, scene_name, hold_duration_ms, max_slots.\n\nMissing from spec:\n- SetSceneItemEnabled for show/hide (currently just text update)\n- Standard slot names from spec (popup-scene-1..4)\n- Transition hooks","created_at":"2026-01-17T23:04:08Z"}]}
{"id":"popup-ai-8sq","title":"Compositor: Cross-Platform Testing \u0026 Validation","description":"Comprehensive testing across all target platforms.\n\n**Platforms:**\n- macOS (Apple Silicon + Intel)\n- Windows 10/11\n- Linux (Ubuntu 22.04+)\n\n**Test Matrix:**\n\n| Test | macOS | Windows | Linux |\n|------|-------|---------|-------|\n| ndi-python install | | | |\n| NDI Tools virtual camera | | | |\n| Webcam capture | | | |\n| SRT input | | | |\n| Screen capture | | | |\n| Text rendering | | | |\n| 30fps sustained | | | |\n| Zoom detection | | | |\n| Meet detection | | | |\n\n**Performance Benchmarks:**\n- CPU usage at 1080p30\n- Memory footprint\n- Latency: annotation → visible in output\n- Frame drop rate under load\n\n**Fallback Validation:**\n- Graceful degradation if NDI runtime missing\n- Clear error messages for common failures\n- OBS mode still works when compositor disabled\n\n**Known Risks:**\n- ndi-python may have platform-specific issues\n- NDI Tools installation varies by platform\n- Camera permissions on macOS Ventura+","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:56:34.126404-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:56:34.126404-05:00","labels":["compositor","speculative"]}
{"id":"popup-ai-9lk","title":"Compositor: CompositorActor Implementation","description":"Main Ray actor orchestrating the compositor pipeline.\n\n**File:** src/popup_ai/actors/compositor.py\n\n**Architecture:**\n```\nInput Queue (Annotations) ──► CompositorActor ──► NDI Output\n                                    │\nVideo Input ─────────────────────────┘\n```\n\n**Actor Responsibilities:**\n1. Initialize video input, NDI output, text renderer\n2. Main loop: get frame → render overlays → send NDI\n3. Process annotation queue (same interface as OverlayActor)\n4. Manage slot state (active, hide_at timestamps)\n5. Health check, start/stop lifecycle\n\n**Key Methods:**\n- start() / stop() - lifecycle\n- _process_loop() - main 30fps render loop\n- _display_annotation() - add annotation to slot\n- _cleanup_loop() - auto-hide expired annotations\n- get_status() - for admin UI\n\n**Config:** CompositorConfig from config.py\n\n**Threading Model:**\n- Main actor thread: Ray actor\n- Video capture: async or separate thread\n- NDI send: blocking but fast\n\n**Drop-in Replacement:**\n- Same input queue interface as OverlayActor\n- OverlayActor can delegate to CompositorActor when compositor enabled","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:56:32.74714-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:56:32.74714-05:00","labels":["compositor","speculative"]}
{"id":"popup-ai-9n9","title":"Epic: Diataxis docs (mkdocs-material) for operating the system","description":"Diataxis documentation framework using mkdocs-material. Documentation written alongside features - every major feature gets tutorial + how-to docs.\n\n**Diataxis quadrants:**\n- **Tutorials**: Learning-oriented, step-by-step lessons for beginners\n- **How-to guides**: Task-oriented, practical steps to achieve specific goals  \n- **Reference**: Information-oriented, technical descriptions (API, config, CLI)\n- **Explanation**: Understanding-oriented, conceptual discussions\n\n**Documentation workflow:**\n1. Feature implementation includes docs subtask\n2. Subagent writes tutorial + how-to for new features\n3. Reference docs auto-generated where possible\n4. Explanation docs written for architecture decisions\n\n**Structure:**\n```\ndocs/\n├── index.md\n├── tutorials/\n│   ├── quickstart.md\n│   ├── first-stream.md\n│   └── ...\n├── how-to/\n│   ├── configure-obs.md\n│   ├── tune-transcription.md\n│   └── ...\n├── reference/\n│   ├── cli.md\n│   ├── config.md\n│   ├── actors.md\n│   └── api.md\n└── explanation/\n    ├── architecture.md\n    ├── ray-actors.md\n    └── ...\n```\n\n**Child issues track individual docs and scaffolding.**","status":"open","priority":2,"issue_type":"feature","owner":"fcorrao@gmail.com","created_at":"2026-01-17T14:10:53.582331-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T18:07:52.173064-05:00"}
{"id":"popup-ai-9n9.1","title":"mkdocs-material scaffolding + CI","description":"Set up mkdocs-material documentation infrastructure.\n\n**Deliverables:**\n1. Add mkdocs-material to dev dependencies\n2. Create mkdocs.yml with:\n   - Material theme config\n   - Navigation structure (tutorials/how-to/reference/explanation)\n   - Search, syntax highlighting, admonitions\n   - GitHub integration\n3. Create docs/ directory structure\n4. Add docs/index.md landing page\n5. GitHub Actions workflow for docs build/deploy\n6. Add `uv run mkdocs serve` to dev workflow\n\n**mkdocs.yml features:**\n- nav with Diataxis sections\n- theme.features: navigation.tabs, navigation.sections, toc.integrate\n- plugins: search, mkdocstrings (for API reference)\n- markdown_extensions: admonition, codehilite, pymdownx.*","status":"closed","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T18:08:10.719538-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T18:43:08.67804-05:00","closed_at":"2026-01-17T18:43:08.67804-05:00","close_reason":"Implemented mkdocs-material scaffolding:\n- Added mkdocs-material, mkdocstrings, mkdocstrings-python to dev deps\n- Created mkdocs.yml with Diataxis nav structure\n- Created docs/ directory with tutorials/how-to/reference/explanation\n- Docs build successfully with 'uv run mkdocs build'","dependencies":[{"issue_id":"popup-ai-9n9.1","depends_on_id":"popup-ai-9n9","type":"parent-child","created_at":"2026-01-17T18:08:10.720134-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-9n9.10","title":"Process: Documentation alongside feature development","description":"Establish workflow for writing docs with features.\n\n**Principle:** Every major feature ships with documentation.\n\n**Workflow:**\n1. Feature issue includes 'Docs' section listing required docs\n2. Implementation includes docs as subtask or acceptance criteria\n3. Before closing feature, verify docs exist\n4. Subagent can be spawned to write docs after implementation\n\n**Doc types per feature:**\n- **Tutorial** if feature is user-facing and learnable\n- **How-to** if feature solves a specific problem\n- **Reference** always (CLI, config, API)\n- **Explanation** if architectural decision\n\n**Subagent prompt template:**\n```\nWrite documentation for [feature]:\n- Read the implementation in [files]\n- Write a tutorial in docs/tutorials/[name].md\n- Write a how-to in docs/how-to/[name].md  \n- Update reference docs if needed\n- Follow Diataxis principles\n- Include code examples that actually work\n```\n\n**Checklist for feature PRs:**\n- [ ] Tutorial written (if applicable)\n- [ ] How-to written (if applicable)\n- [ ] Reference updated\n- [ ] Explanation updated (if architectural)\n\n**This issue:** Add docs section template to feature issue template.","status":"open","priority":1,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T18:09:39.372074-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T18:09:39.372074-05:00","dependencies":[{"issue_id":"popup-ai-9n9.10","depends_on_id":"popup-ai-9n9","type":"parent-child","created_at":"2026-01-17T18:09:39.372745-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-9n9.10","depends_on_id":"popup-ai-9n9.1","type":"blocks","created_at":"2026-01-17T18:09:39.373695-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-9n9.2","title":"Tutorial: Quickstart - first annotation in 5 minutes","description":"Write quickstart tutorial for getting popup-ai running.\n\n**Prerequisites section:**\n- macOS with Apple Silicon\n- OBS Studio installed\n- Python 3.13+\n\n**Steps:**\n1. Install popup-ai: `uv pip install popup-ai[all]`\n2. Start the app: `uv run popup-ai`\n3. Configure OBS for SRT output (brief, link to how-to)\n4. Start streaming in OBS\n5. Watch annotations appear in admin UI\n6. See overlay in OBS\n\n**Outcome:** Reader has working pipeline showing annotations\n\n**Style:**\n- Learning-oriented, encouraging\n- Minimal explanation (link to explanation docs)\n- Screenshots of UI at each step\n- Troubleshooting callouts for common issues","status":"closed","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T18:08:20.481014-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T18:43:16.068412-05:00","closed_at":"2026-01-17T18:43:16.068412-05:00","close_reason":"Written: docs/tutorials/quickstart.md - Step-by-step guide to install, configure OBS, and see first annotation","dependencies":[{"issue_id":"popup-ai-9n9.2","depends_on_id":"popup-ai-9n9","type":"parent-child","created_at":"2026-01-17T18:08:20.48166-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-9n9.2","depends_on_id":"popup-ai-9n9.1","type":"blocks","created_at":"2026-01-17T18:08:20.482526-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-9n9.3","title":"Tutorial: Understanding the admin UI","description":"Tutorial walking through the admin UI features.\n\n**Sections:**\n1. Launching the UI (`popup-ai` vs `popup-ai --headless`)\n2. Actor status dashboard\n   - What each actor does\n   - Health indicators (green/yellow/red)\n   - Stats displayed\n3. Pipeline controls\n   - Start/Stop buttons\n   - What happens when you click them\n4. Live transcript view\n   - How transcripts flow from audio\n   - What the log shows\n5. Recent annotations panel\n   - How annotations are generated\n   - Slot assignment\n6. Settings panel\n   - Audio settings (SRT port, latency)\n   - Transcriber settings (model)\n   - Annotator settings (provider, model)\n   - Overlay settings (OBS connection)\n\n**Outcome:** Reader understands all UI elements and can navigate confidently","status":"closed","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T18:08:29.565929-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T18:43:16.257529-05:00","closed_at":"2026-01-17T18:43:16.257529-05:00","close_reason":"Written: docs/tutorials/admin-ui.md - Guided tour of all UI panels and controls","dependencies":[{"issue_id":"popup-ai-9n9.3","depends_on_id":"popup-ai-9n9","type":"parent-child","created_at":"2026-01-17T18:08:29.56654-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-9n9.3","depends_on_id":"popup-ai-9n9.1","type":"blocks","created_at":"2026-01-17T18:08:29.567407-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-9n9.4","title":"How-to: Configure OBS for SRT streaming to popup-ai","description":"Step-by-step guide for OBS SRT configuration.\n\n**Goal:** Configure OBS to stream audio to popup-ai via SRT\n\n**Steps:**\n1. Open OBS Settings \u003e Stream\n2. Set Service to 'Custom'\n3. Set Server to `srt://localhost:9998?mode=caller\u0026latency=200000`\n4. Configure audio encoding (AAC, 128kbps recommended)\n5. Test connection\n\n**Variations:**\n- Remote streaming (different host)\n- Adjusting latency for your network\n- Multiple audio tracks\n\n**Troubleshooting:**\n- Connection refused: check port, firewall\n- Audio glitches: increase latency\n- No audio: check OBS audio sources\n\n**Related:** Link to explanation of SRT protocol","status":"closed","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T18:08:38.812549-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T21:11:59.823366-05:00","closed_at":"2026-01-17T21:11:59.823366-05:00","close_reason":"Written: docs/tutorials/obs-setup.md - Comprehensive OBS setup guide covering WebSocket configuration, scene/source setup, SRT streaming, and troubleshooting. Also updated existing how-to/configure-obs.md.","dependencies":[{"issue_id":"popup-ai-9n9.4","depends_on_id":"popup-ai-9n9","type":"parent-child","created_at":"2026-01-17T18:08:38.813185-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-9n9.4","depends_on_id":"popup-ai-9n9.1","type":"blocks","created_at":"2026-01-17T18:08:38.814031-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-9n9.5","title":"How-to: Tune transcription settings for accuracy","description":"Guide for optimizing transcription quality.\n\n**Goal:** Improve transcription accuracy for your content\n\n**Settings to adjust:**\n1. Model selection\n   - whisper-base: fast, less accurate\n   - whisper-small: balanced\n   - whisper-medium: slower, more accurate\n   - whisper-large: best accuracy, requires more RAM\n2. Chunk length (chunk_length_s)\n   - Shorter: faster response, may cut words\n   - Longer: better context, more latency\n3. Overlap (overlap_s)\n   - More overlap: smoother transitions\n   - Less overlap: faster processing\n4. Language setting\n   - Auto-detect vs explicit language code\n\n**Tuning workflow:**\n1. Start with defaults\n2. Monitor transcript quality in UI\n3. Adjust one setting at a time\n4. Test with representative content\n\n**Environment variables:**\n- POPUP_TRANSCRIBER_MODEL\n- POPUP_TRANSCRIBER_CHUNK_LENGTH_S\n- POPUP_TRANSCRIBER_OVERLAP_S\n- POPUP_TRANSCRIBER_LANGUAGE","status":"closed","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T18:08:47.547978-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T18:43:16.623498-05:00","closed_at":"2026-01-17T18:43:16.623498-05:00","close_reason":"Written: docs/how-to/tune-transcription.md - Model selection, chunk/overlap settings, language config","dependencies":[{"issue_id":"popup-ai-9n9.5","depends_on_id":"popup-ai-9n9","type":"parent-child","created_at":"2026-01-17T18:08:47.548642-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-9n9.5","depends_on_id":"popup-ai-9n9.1","type":"blocks","created_at":"2026-01-17T18:08:47.549562-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-9n9.6","title":"How-to: Run pipeline subsets (audio-only, transcribe-only)","description":"Guide for running partial pipelines.\n\n**Goal:** Run only the pipeline stages you need\n\n**Use cases:**\n- Audio-only: capture SRT stream without transcription\n- Transcribe-only: process audio files without live ingest\n- No overlay: transcribe without OBS connection\n\n**Via environment variables:**\n```bash\nPOPUP_AUDIO_ENABLED=true\nPOPUP_TRANSCRIBER_ENABLED=true\nPOPUP_ANNOTATOR_ENABLED=false\nPOPUP_OVERLAY_ENABLED=false\n```\n\n**Via CLI (when popup-ai-bjb implemented):**\n```bash\npopup-ai --actors audio,transcriber\npopup-ai --no-overlay\n```\n\n**Via admin UI:**\n1. Start popup-ai\n2. Don't click 'Start Pipeline'\n3. Use individual actor controls (future feature)\n\n**Actor dependencies:**\n- transcriber needs audio (or file input)\n- annotator needs transcriber\n- overlay needs annotator","status":"closed","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T18:08:57.630083-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T23:03:39.994345-05:00","closed_at":"2026-01-17T23:03:39.994345-05:00","close_reason":"Documentation updated at docs/how-to/pipeline-subsets.md to reflect implemented CLI flags (--actors, --no-overlay, etc). Now includes full examples with both CLI and environment variable approaches.","dependencies":[{"issue_id":"popup-ai-9n9.6","depends_on_id":"popup-ai-9n9","type":"parent-child","created_at":"2026-01-17T18:08:57.630725-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-9n9.6","depends_on_id":"popup-ai-9n9.1","type":"blocks","created_at":"2026-01-17T18:08:57.631685-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-9n9.6","depends_on_id":"popup-ai-bjb","type":"blocks","created_at":"2026-01-17T18:08:57.632412-05:00","created_by":"Frank Corrao"}],"comments":[{"id":7,"issue_id":"popup-ai-9n9.6","author":"Frank Corrao","text":"Documentation written at docs/how-to/pipeline-subsets.md. Documents current env var approach and notes CLI flags as future feature (popup-ai-bjb). Will close when CLI flags are implemented.","created_at":"2026-01-17T23:43:30Z"}]}
{"id":"popup-ai-9n9.7","title":"Reference: CLI commands and options","description":"Complete CLI reference documentation.\n\n**Commands:**\n- `popup-ai` - Start with UI (default)\n- `popup-ai --headless` - Start without UI\n- `popup-ai --config PATH` - Use config file\n- `popup-ai --version` - Show version\n- `popup-ai status` - Show pipeline status\n\n**Future commands (per popup-ai-bjb):**\n- `popup-ai --actors LIST`\n- `popup-ai --no-ACTOR`\n\n**Environment variables:**\nDocument all POPUP_* env vars from config.py\n\n**Exit codes:**\n- 0: Success\n- 1: Error (e.g., missing dependencies)\n\n**Auto-generate from typer where possible.**","status":"closed","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T18:09:04.989689-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T18:43:23.66532-05:00","closed_at":"2026-01-17T18:43:23.66532-05:00","close_reason":"Written: docs/reference/cli.md - Complete CLI reference with all options and env vars","dependencies":[{"issue_id":"popup-ai-9n9.7","depends_on_id":"popup-ai-9n9","type":"parent-child","created_at":"2026-01-17T18:09:04.990365-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-9n9.7","depends_on_id":"popup-ai-9n9.1","type":"blocks","created_at":"2026-01-17T18:09:04.991336-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-9n9.8","title":"Reference: Configuration options","description":"Complete configuration reference.\n\n**Sections:**\n\n**AudioIngestConfig (POPUP_AUDIO_*):**\n| Setting | Env Var | Default | Description |\n|---------|---------|---------|-------------|\n| srt_port | POPUP_AUDIO_SRT_PORT | 9998 | SRT listener port |\n| srt_latency_ms | POPUP_AUDIO_SRT_LATENCY_MS | 200 | SRT latency |\n| sample_rate | POPUP_AUDIO_SAMPLE_RATE | 16000 | Audio sample rate |\n| channels | POPUP_AUDIO_CHANNELS | 1 | Audio channels |\n| chunk_duration_ms | POPUP_AUDIO_CHUNK_DURATION_MS | 100 | Chunk size |\n\n**TranscriberConfig (POPUP_TRANSCRIBER_*):**\n| Setting | Env Var | Default | Description |\n|---------|---------|---------|-------------|\n| model | POPUP_TRANSCRIBER_MODEL | mlx-community/whisper-base-mlx | Whisper model |\n| chunk_length_s | POPUP_TRANSCRIBER_CHUNK_LENGTH_S | 5.0 | Processing chunk |\n| overlap_s | POPUP_TRANSCRIBER_OVERLAP_S | 0.5 | Chunk overlap |\n| language | POPUP_TRANSCRIBER_LANGUAGE | None | Language code |\n\n**AnnotatorConfig (POPUP_ANNOTATOR_*):**\n(document all settings)\n\n**OverlayConfig (POPUP_OVERLAY_*):**\n(document all settings)\n\n**PipelineConfig (POPUP_*):**\n(document all settings)\n\n**Auto-generate from pydantic-settings models.**","status":"closed","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T18:09:17.598979-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T18:43:23.865347-05:00","closed_at":"2026-01-17T18:43:23.865347-05:00","close_reason":"Written: docs/reference/configuration.md - All config sections with env vars and defaults","dependencies":[{"issue_id":"popup-ai-9n9.8","depends_on_id":"popup-ai-9n9","type":"parent-child","created_at":"2026-01-17T18:09:17.599615-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-9n9.8","depends_on_id":"popup-ai-9n9.1","type":"blocks","created_at":"2026-01-17T18:09:17.600539-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-9n9.9","title":"Explanation: Ray Actor architecture","description":"Conceptual explanation of the Ray Actor architecture.\n\n**Topics:**\n\n1. **Why Ray Actors?**\n   - Modular monolith pattern\n   - Each pipeline stage isolated\n   - Fault isolation and restart\n   - Async communication via queues\n\n2. **Actor overview:**\n   - PipelineSupervisor: orchestrates lifecycle\n   - AudioIngestActor: ffmpeg SRT capture\n   - TranscriberActor: mlx-whisper STT\n   - AnnotatorActor: pydantic-ai LLM\n   - OverlayActor: OBS websocket\n\n3. **Data flow:**\n   ```\n   SRT → AudioIngest → [audio_queue] → Transcriber → [transcript_queue] \n       → Annotator → [annotation_queue] → Overlay → OBS\n   ```\n\n4. **Message types:**\n   - AudioChunk, Transcript, Annotation\n   - UIEvent for admin UI updates\n\n5. **Supervision:**\n   - Health monitoring loop\n   - Automatic restart on crash\n   - Graceful shutdown\n\n6. **UI integration:**\n   - UI runs in main process\n   - Communicates via actor handles\n   - Subscribes to UI event queue\n\n**Diagrams:** Include ASCII art from architecture doc","status":"closed","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T18:09:27.573932-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T18:43:24.052729-05:00","closed_at":"2026-01-17T18:43:24.052729-05:00","close_reason":"Written: docs/explanation/architecture.md and docs/explanation/ray-actors.md - Full architecture explanation with diagrams","dependencies":[{"issue_id":"popup-ai-9n9.9","depends_on_id":"popup-ai-9n9","type":"parent-child","created_at":"2026-01-17T18:09:27.574595-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-9n9.9","depends_on_id":"popup-ai-9n9.1","type":"blocks","created_at":"2026-01-17T18:09:27.575511-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-aby","title":"Slide/Screen OCR Context","description":"OCR current slide/screen, use as additional context for annotations. Periodic screen capture to OCR (Tesseract or vision LLM), inject as context to Annotator. Detect slide changes and auto-annotate new terms.","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:35:14.161292-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:35:14.161292-05:00","labels":["speculative","vision"]}
{"id":"popup-ai-ahl","title":"Admin UI (NiceGUI)","description":"NiceGUI admin UI: live transcript, annotation queue, OBS connection state, and manual controls (trigger show/hide, override slot content). Include prompt editor and STT tuning controls (chunk/overlap/thresholds). All UI-editable settings persist to SQLite and reload on startup. Add panels to run pipeline in parts (ingest-only, record-only, transcribe-only, annotate-only).","status":"open","priority":2,"issue_type":"feature","owner":"fcorrao@gmail.com","created_at":"2026-01-17T13:54:11.641988-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T15:43:37.782059-05:00","dependencies":[{"issue_id":"popup-ai-ahl","depends_on_id":"popup-ai-445","type":"blocks","created_at":"2026-01-17T13:55:48.347394-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-ahl","depends_on_id":"popup-ai-f33","type":"blocks","created_at":"2026-01-17T15:43:46.374817-05:00","created_by":"Frank Corrao"}],"comments":[{"id":3,"issue_id":"popup-ai-ahl","author":"Frank Corrao","text":"Initial NiceGUI admin UI implemented in src/popup_ai/ui/app.py:\n- Actor status dashboard with health indicators\n- Pipeline start/stop controls\n- Live transcript view (subscribes to UI queue)\n- Recent annotations display\n- Settings panel for audio/transcriber/annotator/overlay config\n\nMissing from spec:\n- Manual overlay controls (trigger show/hide, override slot)\n- Prompt editor\n- STT tuning controls\n- SQLite settings persistence (currently in-memory only)\n- Individual actor panels for partial pipeline runs\n\nArchitecture note: Using NiceGUI with Ray actor handles directly instead of FastAPI. UI communicates via supervisor methods and UI event queue.","created_at":"2026-01-17T23:03:22Z"}]}
{"id":"popup-ai-apr","title":"Audio preprocessing pipeline (VAD, normalization, silence trimming)","description":"Add configurable audio preprocessing before Whisper transcription.\n\n**Components:**\n1. **VAD (Voice Activity Detection)** - Silero VAD\n   - Detect speech vs silence/noise\n   - Only send voiced segments to Whisper\n   - Reduces hallucinations and processing load\n   - Config: vad_enabled, vad_threshold (0.0-1.0), vad_min_speech_ms, vad_min_silence_ms\n\n2. **Silence Trimming**\n   - Remove leading/trailing silence from chunks\n   - Keep buffer around speech (100ms default)\n   - Config: silence_trim_enabled, silence_threshold_db (-20 default), silence_buffer_ms\n\n3. **Volume Normalization**\n   - Zero-mean unit-variance normalization\n   - Improves Whisper accuracy per docs\n   - Config: normalize_enabled, normalize_target_db\n\n4. **NOT implementing noise reduction** - Research shows it often degrades ASR quality\n\n**Implementation:**\n- New AudioPreprocessor class in src/popup_ai/actors/audio_preprocessor.py\n- Or integrate into TranscriberActor before Whisper call\n- All settings exposed in admin UI under Transcriber settings\n- Settings persisted to SQLite\n\n**Dependencies:**\n- silero-vad (or use webrtcvad as lighter alternative)\n- numpy for signal processing\n- pydub or librosa for audio manipulation\n\n**References:**\n- https://github.com/SYSTRAN/faster-whisper (VAD integration)\n- https://github.com/m-bain/whisperX (VAD + batching)\n- https://github.com/openai/whisper/discussions/2125 (preprocessing discussion)","status":"open","priority":2,"issue_type":"feature","owner":"fcorrao@gmail.com","created_at":"2026-01-18T04:55:00-05:00","created_by":"Frank Corrao","updated_at":"2026-01-18T04:55:00-05:00","dependencies":[{"issue_id":"popup-ai-apr","depends_on_id":"popup-ai-05k","type":"blocks","created_at":"2026-01-18T04:55:00-05:00","created_by":"Frank Corrao"}],"comments":[{"id":10,"issue_id":"popup-ai-apr","author":"Frank Corrao","text":"**Architectural Decision: Preprocessing in TranscriberActor, NOT separate actor**\n\nAnalyzed whether to make preprocessing its own Ray actor. Decision: NO.\n\n**Reasons:**\n1. Latency - Another queue hop adds latency. Targeting 5s E2E, every ms matters\n2. VAD is fast - Silero VAD processes 30s audio in \u003c1ms on CPU. Not worth actor overhead\n3. Conceptually coupled - Preprocessing is 'preparing audio for Whisper', not separate stage\n4. Industry practice - faster-whisper and WhisperX integrate VAD inline, not separate\n5. Memory copies - Audio data would be copied through another queue unnecessarily\n\n**Pipeline boundary analysis:**\n- AudioIngest (I/O bound: ffmpeg subprocess, SRT capture)\n- Transcriber (CPU/GPU bound: preprocessing + Whisper) ← preprocessing goes here\n- Annotator (network bound: LLM API)\n- Overlay (network bound: OBS websocket)\n\nPreprocessing fits naturally in Transcriber - all CPU-bound audio processing before model.","created_at":"2026-01-18T05:05:00Z"}]}
{"id":"popup-ai-bjb","title":"CLI options for launching pipeline subsets","description":"Add CLI options to enable/disable specific actors at startup. The PipelineSupervisor already supports per-actor enable/disable via settings (audio_enabled, transcriber_enabled, annotator_enabled, overlay_enabled), but we need CLI flags to control this.\n\n**Proposed CLI:**\n```\npopup-ai --actors audio,transcriber    # Only audio ingest + transcription\npopup-ai --no-overlay                  # Full pipeline except overlay\npopup-ai --only transcriber            # Just transcriber (from file input)\n```\n\n**Implementation:**\n1. Add --actors flag (comma-separated list of actors to enable)\n2. Add --no-\u003cactor\u003e flags for disabling specific actors\n3. Map CLI flags to PipelineConfig.{actor}_enabled settings\n4. Validate actor dependencies (e.g., annotator needs transcriber)\n\n**Existing support:**\n- PipelineSupervisor.start() checks settings.pipeline.{actor}_enabled\n- PipelineSupervisor.start_actor(name) / stop_actor(name) for individual control\n- UI already has actor-level start/stop controls","status":"closed","priority":2,"issue_type":"feature","owner":"fcorrao@gmail.com","created_at":"2026-01-17T18:02:21.372245-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T23:01:04.808442-05:00","closed_at":"2026-01-17T23:01:04.808442-05:00","close_reason":"Implemented CLI options for pipeline subsets:\n- Added --actors flag for comma-separated list of actors to enable\n- Added --no-audio, --no-transcriber, --no-annotator, --no-overlay flags\n- Applied flags update PipelineConfig settings before supervisor starts\n- Shows enabled actors on startup\n- Warns if no actors enabled\n- Unit tests added in tests/test_actors.py::TestCLIActorFlags"}
{"id":"popup-ai-bx7","title":"Chat/Q\u0026A Integration","description":"Pull questions from Twitch/YouTube chat, answer via overlay. ChatIngestActor connects to chat APIs, filters for questions (? or !explain), routes to Annotator with Q\u0026A prompt, displays as special styled annotation.","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:35:13.773499-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:35:13.773499-05:00","labels":["interactive","speculative"]}
{"id":"popup-ai-dyf","title":"Knowledge Graph / Term Relationships","description":"Build graph of explained terms over time, show relationships. Store annotations with timestamps in SQLite. LLM prompt asks how terms relate to previously explained terms. End-of-stream summary visualization.","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:34:53.290428-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:34:53.290428-05:00","labels":["intelligence","speculative"]}
{"id":"popup-ai-e90","title":"Project scaffolding: uv + hatchling + pyproject baseline","description":"Project scaffolding: uv-managed pyproject baseline, hatchling build backend, scripts/entrypoints, lockfile handling for server/UI tooling.","status":"closed","priority":2,"issue_type":"feature","owner":"fcorrao@gmail.com","created_at":"2026-01-17T13:53:04.983001-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T17:15:40.973925-05:00","closed_at":"2026-01-17T17:15:40.973925-05:00","close_reason":"Closed"}
{"id":"popup-ai-eic","title":"Interactive QR Codes","description":"Generate QR codes linking to deeper content (Wikipedia, docs). Annotator extracts term + generates search URL, QR library generates image, display in dedicated OBS image source slot.","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:34:53.468287-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:34:53.468287-05:00","labels":["interactive","speculative"]}
{"id":"popup-ai-ekz","title":"Custom Lightweight Video Compositor","description":"Replace OBS with a custom, lightweight NDI-based compositor that handles only what popup-ai needs, making user setup dramatically simpler.\n\n## Goal\nReduce user setup from 7 steps (OBS) to 3 steps (NDI Tools + run popup-ai).\n\n## Architecture\n- Video input via PyAV (SRT) or OpenCV (webcam)\n- PIL/Pillow for text rendering (reuse slot logic from OverlayActor)\n- NDI output via ndi-python\n- User installs NDI Tools (~50MB) for virtual camera\n\n## Key Benefits\n- No OBS configuration required\n- Cross-platform (macOS, Linux, Windows)\n- Much lighter than OBS (~50MB vs ~300MB)\n- NDI Tools provides virtual camera for Zoom/Meet","status":"open","priority":1,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:58:15.124588-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:58:15.124588-05:00"}
{"id":"popup-ai-ekz.1","title":"Create NDI output wrapper (ndi_output.py)","description":"Create src/popup_ai/ndi_output.py - NDI sender wrapper using ndi-python.\n\n- Source name: 'popup-ai' (appears in NDI Tools/Zoom)\n- BGRA format (NDI native)\n- Handle connection/disconnection gracefully\n- Frame rate management (30fps target)","status":"open","priority":1,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:58:22.214541-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:58:22.214541-05:00","dependencies":[{"issue_id":"popup-ai-ekz.1","depends_on_id":"popup-ai-ekz","type":"parent-child","created_at":"2026-01-19T15:58:22.215215-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-ekz.2","title":"Create video input abstraction (video_input.py)","description":"Create src/popup_ai/video_input.py - Video source abstraction.\n\nSources to support:\n- Webcam via OpenCV\n- SRT stream via PyAV\n- Screen capture via mss (optional, Phase 3)\n\nCommon interface for all sources.","status":"open","priority":1,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:58:27.371267-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:58:27.371267-05:00","dependencies":[{"issue_id":"popup-ai-ekz.2","depends_on_id":"popup-ai-ekz","type":"parent-child","created_at":"2026-01-19T15:58:27.371894-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-ekz.3","title":"Create CompositorActor (compositor.py)","description":"Create src/popup_ai/actors/compositor.py - Main compositor Ray actor.\n\nComponents:\n- Video frame loop (30fps)\n- Text overlay rendering with PIL/Pillow\n- Multiple text slots with positioning (reuse slot logic from OverlayActor)\n- Scrolling text via frame-by-frame position updates\n- Integration with video_input.py and ndi_output.py\n\nShould expose same slot-based API as current OverlayActor for compatibility.","status":"open","priority":1,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:58:34.072804-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:58:34.072804-05:00","dependencies":[{"issue_id":"popup-ai-ekz.3","depends_on_id":"popup-ai-ekz","type":"parent-child","created_at":"2026-01-19T15:58:34.073437-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-ekz.3","depends_on_id":"popup-ai-ekz.1","type":"blocks","created_at":"2026-01-19T15:59:11.303669-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-ekz.3","depends_on_id":"popup-ai-ekz.2","type":"blocks","created_at":"2026-01-19T15:59:11.367877-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-ekz.3","depends_on_id":"popup-ai-ekz.4","type":"blocks","created_at":"2026-01-19T15:59:11.430963-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-ekz.3","depends_on_id":"popup-ai-ekz.5","type":"blocks","created_at":"2026-01-19T15:59:11.49437-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-ekz.4","title":"Add CompositorConfig to config.py","description":"Add compositor configuration to src/popup_ai/config.py.\n\nOptions:\n- enabled: bool = False (OBS mode default)\n- video_source: Literal['srt', 'webcam', 'screen'] = 'webcam'\n- srt_url: str = 'srt://0.0.0.0:9998'\n- webcam_index: int = 0\n- resolution: tuple[int, int] = (1920, 1080)\n- fps: int = 30\n- ndi_source_name: str = 'popup-ai'\n\nAdd to Settings root container.","status":"open","priority":1,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:58:41.371274-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:58:41.371274-05:00","dependencies":[{"issue_id":"popup-ai-ekz.4","depends_on_id":"popup-ai-ekz","type":"parent-child","created_at":"2026-01-19T15:58:41.371971-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-ekz.5","title":"Add compositor dependencies to pyproject.toml","description":"Add new dependencies to pyproject.toml:\n\n- ndi-python (NDI output)\n- av (PyAV - video decode/encode)\n- opencv-python (webcam capture)\n- Pillow (text rendering, may already exist)\n- mss (screen capture, optional)","status":"open","priority":1,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:58:46.141526-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:58:46.141526-05:00","dependencies":[{"issue_id":"popup-ai-ekz.5","depends_on_id":"popup-ai-ekz","type":"parent-child","created_at":"2026-01-19T15:58:46.142187-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-ekz.6","title":"Modify OverlayActor for compositor backend","description":"Modify src/popup_ai/actors/overlay.py to support compositor backend.\n\n- Add backend selection (OBS vs compositor)\n- When compositor mode enabled, delegate to CompositorActor instead of OBS\n- Maintain same public API for compatibility with rest of pipeline","status":"open","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:58:54.993131-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:58:54.993131-05:00","dependencies":[{"issue_id":"popup-ai-ekz.6","depends_on_id":"popup-ai-ekz","type":"parent-child","created_at":"2026-01-19T15:58:54.993754-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-ekz.6","depends_on_id":"popup-ai-ekz.3","type":"blocks","created_at":"2026-01-19T15:59:11.56127-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-ekz.7","title":"Add compositor settings to Admin UI","description":"Add compositor configuration panel to admin UI.\n\nSettings to expose:\n- Enable/disable compositor mode\n- Video source selection (webcam/SRT/screen)\n- Webcam device picker\n- Resolution and FPS settings\n- NDI source name","status":"open","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:59:00.358053-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:59:00.358053-05:00","dependencies":[{"issue_id":"popup-ai-ekz.7","depends_on_id":"popup-ai-ekz","type":"parent-child","created_at":"2026-01-19T15:59:00.358712-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-ekz.7","depends_on_id":"popup-ai-ekz.6","type":"blocks","created_at":"2026-01-19T15:59:11.6305-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-ekz.8","title":"Cross-platform testing (macOS, Linux, Windows)","description":"Test compositor on all three platforms:\n\n1. Verify ndi-python works on each platform\n2. Verify NDI Tools virtual camera integration\n3. Test webcam capture on each platform\n4. Verify virtual camera appears in Zoom/Meet\n5. Performance testing (30fps sustained)","status":"open","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:59:06.13589-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:59:06.13589-05:00","dependencies":[{"issue_id":"popup-ai-ekz.8","depends_on_id":"popup-ai-ekz","type":"parent-child","created_at":"2026-01-19T15:59:06.136502-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-ekz.8","depends_on_id":"popup-ai-ekz.3","type":"blocks","created_at":"2026-01-19T15:59:11.69637-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-f33","title":"Modular run modes (ingest/record/transcribe/annotate)","description":"Define architecture for running pipeline in parts: ingest-only (SRT-\u003ePCM stream), record-only (SRT-\u003eaudio file), transcribe-only (file-\u003etranscript), annotate-only (text-\u003eannotation), and full pipeline. Ensure services are decoupled and composable; expose via CLI + admin UI.\n\n**REVISION NEEDED (2026-01-17):** Initial implementation was wrong - created CLI modes as separate execution paths. Should be internal pipeline stage toggles managed via event bus in modular monolith. See popup-ai-nsa for architecture spike. This issue blocked until architecture is finalized.","status":"closed","priority":2,"issue_type":"feature","owner":"fcorrao@gmail.com","created_at":"2026-01-17T15:43:26.338117-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T18:03:10.373075-05:00","closed_at":"2026-01-17T18:03:10.373075-05:00","close_reason":"Implemented via Ray actor architecture. Pipeline stages are now actors (AudioIngest, Transcriber, Annotator, Overlay) that can be enabled/disabled via PipelineConfig settings. Supervisor manages lifecycle. Remaining CLI work tracked in popup-ai-bjb (CLI options for launching pipeline subsets).","dependencies":[{"issue_id":"popup-ai-f33","depends_on_id":"popup-ai-nsa","type":"blocks","created_at":"2026-01-17T17:28:45.894777-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-fby","title":"Sentiment/Emotion Indicator","description":"Visual indicator of speaker emotional tone. Sentiment model runs on transcript (simple classification), display subtle color bar or emoji in corner. Could use audio features for realtime affect detection.","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:35:14.351747-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:35:14.351747-05:00","labels":["intelligence","speculative"]}
{"id":"popup-ai-h5a","title":"Speaker Diarization \u0026 Attribution","description":"Identify multiple speakers using pyannote-audio, attribute annotations with visual differentiation. Track speaker embeddings, assign consistent IDs, color-code annotations by speaker.","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:34:53.11136-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:34:53.11136-05:00","labels":["audio","speculative"]}
{"id":"popup-ai-nsa","title":"Architecture spike: modular monolith with event bus","description":"BLOCKING: Rethink architecture before further implementation.\n\nCurrent design is wrong - treats run modes as separate execution paths and UI as separate command. Need modular monolith instead:\n\n**Target architecture:**\n- Single process, UI always available (NiceGUI)\n- Lightweight internal event bus for component communication\n- Pipeline stages as application-scoped services (AudioIngest, Transcriber, Annotator, OverlayController)\n- Stages enabled/disabled via config/UI, not CLI modes\n- Event channels: audio_chunks, transcripts, annotations, overlay_commands\n\n**CLI simplification:**\n- `popup-ai` starts app with UI + pipeline\n- `--headless` flag for no-UI operation\n- Pipeline configuration via settings, not execution modes\n\n**Deliverables:**\n1. Event bus design (asyncio queues? simple pub/sub?)\n2. Service lifecycle management\n3. Updated module structure\n4. Revised CLI","status":"closed","priority":1,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T17:28:13.385964-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T17:53:12.816372-05:00","closed_at":"2026-01-17T17:53:12.816372-05:00","close_reason":"Implemented Ray Actor architecture with:\n- PipelineSupervisor actor with health monitoring and automatic restart\n- AudioIngestActor (ffmpeg SRT→PCM)\n- TranscriberActor (mlx-whisper)\n- AnnotatorActor (pydantic-ai + SQLite cache)\n- OverlayActor (OBS websocket)\n- NiceGUI admin UI with actor status, controls, live transcript\n- pydantic-settings config with per-actor sections\n- CLI: popup-ai (with UI) / popup-ai --headless\n- Ray Queues for inter-actor communication\n- Deleted obsolete modes.py"}
{"id":"popup-ai-nyq","title":"Compositor: Documentation \u0026 Setup Guide","description":"User-facing documentation for the custom compositor.\n\n**Docs to Create:**\n\n1. **Quick Start Guide:**\n   - Install NDI Tools (link + platform-specific instructions)\n   - Enable compositor in popup-ai config\n   - Select 'popup-ai' in Zoom/Meet camera settings\n\n2. **Troubleshooting:**\n   - NDI source not appearing → Check NDI runtime installed\n   - Low FPS → Reduce resolution, check CPU usage\n   - Black screen → Check video source configuration\n   - Audio out of sync → Buffer settings\n\n3. **Configuration Reference:**\n   - All CompositorConfig options\n   - Environment variables\n   - Example configs for common scenarios\n\n4. **Architecture Overview:**\n   - Diagram: video input → compositor → NDI → virtual camera\n   - When to use compositor vs OBS mode\n   - Performance characteristics\n\n**Location:** docs/tutorials/compositor-setup.md or similar","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:56:33.84364-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:56:33.84364-05:00","labels":["compositor","speculative"]}
{"id":"popup-ai-o34","title":"Image Generation for Annotations","description":"Generate illustrative images for key terms via SDXL Turbo or Flux Schnell. ImageGenActor uploads to CDN, OBS browser source displays. Text shows immediately, image appears 3-5s later in adjacent slot.","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:34:52.930419-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:34:52.930419-05:00","labels":["speculative","vision"]}
{"id":"popup-ai-pnf","title":"Custom Lightweight Compositor - Core Architecture","description":"Replace OBS with a custom lightweight compositor using NDI for virtual camera output.\n\n**Goal:** Reduce user setup from 7 steps (OBS) to 3 steps (NDI Tools + run popup-ai + select camera).\n\n**Architecture:**\n- CompositorActor (Ray) handles video input → frame manipulation → NDI output\n- ndi-python for NDI output (appears as 'popup-ai' source in Zoom/Meet)\n- NDI Tools (free, ~50MB) provides virtual camera on all platforms\n- Keep existing audio pipeline for transcription\n\n**Why NDI over custom virtual camera:**\n- NDI SDK is royalty-free for commercial use\n- NDI Tools is free, cross-platform, much lighter than OBS\n- ndi-python is pip-installable\n- Avoids platform-specific camera driver development (1-2 months per platform)\n\n**User Experience After:**\n1. Download NDI Tools (one-time)\n2. Run popup-ai\n3. Select 'popup-ai' as camera in Zoom/Meet\n\n**Effort Estimate:** 6-8 weeks total for complete OBS replacement","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:55:36.694041-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:55:36.694041-05:00","labels":["compositor","speculative"]}
{"id":"popup-ai-q4w","title":"Base prompt template (pydantic-ai)","description":"Draft initial prompt template and output schema for pydantic-ai (role/goal, annotation constraints, JSON schema), with runtime editability via admin UI.","status":"open","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T16:57:03.124694-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T16:57:03.124694-05:00","dependencies":[{"issue_id":"popup-ai-q4w","depends_on_id":"popup-ai-w5n","type":"blocks","created_at":"2026-01-17T16:57:07.493553-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-qat","title":"SQLite cache for prompt+term -\u003e annotation","description":"SQLite cache for prompt+term -\u003e annotation. **Schema proposal:** table annotations_cache(id INTEGER PK, term_norm TEXT, prompt_hash TEXT, context_hash TEXT NULL, result_text TEXT, model TEXT, provider TEXT, created_at DATETIME, last_accessed DATETIME, hit_count INT). Index on (prompt_hash, term_norm, context_hash). **Behavior:** normalize term (lower/strip/punct), hash prompt template + system prompt + model/provider, include optional context hash (e.g., topic). Cache lookup before LLM; update hit_count/last_accessed. v1: unlimited size, no TTL/eviction; cache controls (enable/disable, clear) exposed in admin UI and persisted.","status":"in_progress","priority":2,"issue_type":"feature","owner":"fcorrao@gmail.com","created_at":"2026-01-17T15:19:46.176506-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T18:02:37.039428-05:00","comments":[{"id":1,"issue_id":"popup-ai-qat","author":"Frank Corrao","text":"Basic SQLite cache implemented in AnnotatorActor (src/popup_ai/actors/annotator.py). Current schema: annotations(text_hash, term, explanation, created_at). Uses SHA256 hash of transcript text. Cache lookup before LLM call. Missing from full spec: term normalization, prompt hash, context hash, hit_count tracking, model/provider columns, UI controls for cache enable/clear.","created_at":"2026-01-17T23:02:47Z"}]}
{"id":"popup-ai-qdo","title":"Integration testing for Ray actor pipeline","description":"Create integration tests for the Ray actor pipeline to verify:\n\n1. **Actor lifecycle:**\n   - Actors start/stop cleanly\n   - Health checks work correctly\n   - Automatic restart on crash works\n\n2. **Data flow:**\n   - AudioChunk flows from AudioIngest → Transcriber\n   - Transcript flows from Transcriber → Annotator\n   - Annotation flows from Annotator → Overlay\n   - UIEvents flow to UI queue\n\n3. **Mock actors for testing:**\n   - MockAudioIngestActor (generates test audio chunks)\n   - MockTranscriberActor (returns canned transcripts)\n   - MockAnnotatorActor (returns canned annotations)\n   - MockOverlayActor (logs received annotations)\n\n4. **Test scenarios:**\n   - Full pipeline end-to-end\n   - Individual actor start/stop\n   - Actor crash and recovery\n   - Queue backpressure handling\n\n**Files to create:**\n- tests/test_actors.py\n- tests/conftest.py (Ray fixtures)\n- tests/mocks.py (mock actors)","status":"open","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-17T18:02:32.644722-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T18:02:32.644722-05:00","comments":[{"id":9,"issue_id":"popup-ai-qdo","author":"Frank Corrao","text":"Created test infrastructure:\n- tests/conftest.py: Ray fixtures, test configs\n- tests/mocks.py: Mock actors for testing (MockAudioIngestActor, MockTranscriberActor, MockAnnotatorActor, MockOverlayActor)\n- tests/test_actors.py: Integration tests\n\nTests implemented:\n- TestAudioIngestActor: ffmpeg availability check\n- TestMockPipeline: Mock pipeline data flow (skipped due to Ray/pytest issues)\n- TestActorHealthCheck: Health check behavior (skipped)\n- TestPipelineSupervisor: Supervisor lifecycle (skipped)\n- TestUIEvents: UI event flow (skipped)\n- TestCLIActorFlags: CLI flag parsing and application (6 passing tests)\n\nNote: Ray tests skipped in pytest environment due to Ray initialization issues. Can run manually with 'uv run python' script.","created_at":"2026-01-18T04:03:14Z"}]}
{"id":"popup-ai-qvr","title":"Prepared Notes Integration","description":"Host pre-writes notes, system displays them at right moment. Load notes file with keyword triggers, when keyword detected in transcript display prepared note. Allows polished explanations for anticipated topics.","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:35:14.730963-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:35:14.730963-05:00","labels":["annotator","speculative"]}
{"id":"popup-ai-skk","title":"Overlay slot scheduler + transition sequencing","description":"Overlay slot scheduler: 4-slot round-robin allocator, default hold_ms=5000. Sequence update-\u003eshow-\u003ehide (v1 no transitions).","status":"open","priority":2,"issue_type":"feature","owner":"fcorrao@gmail.com","created_at":"2026-01-17T14:52:28.28795-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T15:19:58.159152-05:00","dependencies":[{"issue_id":"popup-ai-skk","depends_on_id":"popup-ai-4cs","type":"blocks","created_at":"2026-01-17T14:52:38.000474-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-u8o","title":"Pre-Filter for Technical Term Identification","description":"Small/fast LLMs often miss identifying technical terms. Add a fast (\u003c10ms) pre-filter that identifies candidate terms before LLM, using: 1) Pattern matching (regex), 2) Dictionary lookup (curated glossary), 3) Statistical rarity check. Can skip LLM entirely if no candidates, or pass candidates to constrain LLM output.","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T19:52:47.549785-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T19:52:47.549785-05:00","labels":["annotator","enhancement"]}
{"id":"popup-ai-u8o.1","title":"Core Pre-Filter Implementation","description":"Create src/popup_ai/prefilter.py with TechTermPrefilter class. Three-layer detection: 1) Pattern matching (camelCase, ACRONYMS, snake_case), 2) Glossary lookup (curated ~500 tech terms), 3) Rarity check (words not in top 5k English). Method: find_candidates(text) -\u003e list[str]. Target: \u003c10ms execution.","status":"open","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T19:52:54.602336-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T19:52:54.602336-05:00","labels":["annotator"],"dependencies":[{"issue_id":"popup-ai-u8o.1","depends_on_id":"popup-ai-u8o","type":"parent-child","created_at":"2026-01-19T19:52:54.602994-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-u8o.2","title":"Annotator Integration","description":"Integrate pre-filter into _process_transcript() in annotator.py. After cache check, before LLM call: run prefilter, if no candidates skip LLM entirely, otherwise pass to LLM. Add 'prefilter_skip' UI event for observability.","status":"open","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T19:53:06.234444-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T19:53:06.234444-05:00","labels":["annotator"],"dependencies":[{"issue_id":"popup-ai-u8o.2","depends_on_id":"popup-ai-u8o","type":"parent-child","created_at":"2026-01-19T19:53:06.235106-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-u8o.2","depends_on_id":"popup-ai-u8o.1","type":"blocks","created_at":"2026-01-19T19:53:06.236247-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-u8o.3","title":"Constrained LLM Mode","description":"Add constrained prompt mode: pass candidate terms to LLM to focus output. New prompt template: 'These terms may be technical jargon: {candidates}. For each that appears and would confuse a non-programmer, provide explanation.'","status":"open","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T19:53:06.305453-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T19:53:06.305453-05:00","labels":["annotator"],"dependencies":[{"issue_id":"popup-ai-u8o.3","depends_on_id":"popup-ai-u8o","type":"parent-child","created_at":"2026-01-19T19:53:06.306105-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-u8o.3","depends_on_id":"popup-ai-u8o.1","type":"blocks","created_at":"2026-01-19T19:53:06.307257-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-u8o.4","title":"Pre-filter Configuration","description":"Add to AnnotatorConfig: prefilter_enabled (bool, default True), prefilter_constrain_llm (bool, default True), prefilter_min_candidates (int, default 1). Configurable via env vars.","status":"open","priority":2,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T19:53:06.375846-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T19:53:06.375846-05:00","labels":["annotator","config"],"dependencies":[{"issue_id":"popup-ai-u8o.4","depends_on_id":"popup-ai-u8o","type":"parent-child","created_at":"2026-01-19T19:53:06.376496-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-u8o.5","title":"External Glossary File Support","description":"Load custom glossary from ~/.popup-ai/glossary.txt. One term per line, supports comments (#). Hot-reload on file change. Custom glossary extends built-in terms.","status":"open","priority":3,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T19:53:14.860059-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T19:53:14.860059-05:00","labels":["annotator","optional"],"dependencies":[{"issue_id":"popup-ai-u8o.5","depends_on_id":"popup-ai-u8o","type":"parent-child","created_at":"2026-01-19T19:53:14.860751-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-u8o.5","depends_on_id":"popup-ai-u8o.1","type":"blocks","created_at":"2026-01-19T19:53:14.862073-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-u8o.6","title":"Pre-filter UI Integration","description":"Show prefilter status in Annotator tab: display 'Candidates: X, Y, Z' in input viewer, show prefilter skip count in stats, add toggle for prefilter enabled/constrained in settings panel.","status":"open","priority":3,"issue_type":"task","owner":"fcorrao@gmail.com","created_at":"2026-01-19T19:53:14.928448-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T19:53:14.928448-05:00","labels":["annotator","optional","ui"],"dependencies":[{"issue_id":"popup-ai-u8o.6","depends_on_id":"popup-ai-u8o","type":"parent-child","created_at":"2026-01-19T19:53:14.929113-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-u8o.6","depends_on_id":"popup-ai-u8o.2","type":"blocks","created_at":"2026-01-19T19:53:14.930469-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-v23","title":"Compositor: Configuration \u0026 Integration","description":"Configuration schema and integration with existing pipeline.\n\n**Files to Modify:**\n- src/popup_ai/config.py - Add CompositorConfig\n- src/popup_ai/actors/overlay.py - Backend selection\n- pyproject.toml - New dependencies\n\n**CompositorConfig:**\n```python\nclass CompositorConfig(BaseSettings):\n    model_config = SettingsConfigDict(env_prefix='POPUP_COMPOSITOR_')\n    \n    enabled: bool = False  # Off by default, OBS mode\n    video_source: Literal['srt', 'webcam', 'screen'] = 'webcam'\n    srt_url: str = 'srt://0.0.0.0:9998'\n    webcam_index: int = 0\n    screen_region: tuple[int, int, int, int] | None = None\n    resolution: tuple[int, int] = (1920, 1080)\n    fps: int = 30\n    ndi_source_name: str = 'popup-ai'\n    \n    # Text rendering\n    font_path: str | None = None  # Use system default\n    font_size: int = 32\n    text_color: str = '#FFFFFF'\n    bg_color: str = '#000000CC'  # Semi-transparent black\n```\n\n**OverlayActor Changes:**\n- Add backend selection: 'obs' | 'compositor'\n- When compositor enabled, delegate to CompositorActor\n- Keep OBS mode as fallback for advanced users\n\n**New Dependencies:**\n- ndi-python\n- opencv-python\n- mss (optional)\n- Pillow (already present?)","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:56:33.032624-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:56:33.032624-05:00","labels":["compositor","speculative"]}
{"id":"popup-ai-w5n","title":"LLM orchestration (pydantic-ai) + provider adapters","description":"LLM orchestration with pydantic-ai producing single AnnotationEvent per term; tool calls target overlay scheduler (show/update/hide). Integrate SQLite cache (popup-ai-qat) for prompt+term results. Support runtime prompt editing from admin UI (persisted). Track base prompt template in popup-ai-q4w.","status":"open","priority":2,"issue_type":"feature","owner":"fcorrao@gmail.com","created_at":"2026-01-17T13:53:56.617312-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T16:57:21.751325-05:00","dependencies":[{"issue_id":"popup-ai-w5n","depends_on_id":"popup-ai-05k","type":"blocks","created_at":"2026-01-17T13:55:26.38845-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-w5n","depends_on_id":"popup-ai-8iq","type":"blocks","created_at":"2026-01-17T13:55:33.417636-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-w5n","depends_on_id":"popup-ai-qat","type":"blocks","created_at":"2026-01-17T15:20:05.27167-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-w5n","depends_on_id":"popup-ai-f33","type":"blocks","created_at":"2026-01-17T15:43:46.263705-05:00","created_by":"Frank Corrao"}],"comments":[{"id":5,"issue_id":"popup-ai-w5n","author":"Frank Corrao","text":"AnnotatorActor implemented in src/popup_ai/actors/annotator.py:\n- Uses pydantic-ai Agent with structured output (list[AnnotationResult])\n- Pulls Transcripts from Ray Queue\n- Checks SQLite cache before LLM call\n- Caches results after successful LLM call\n- Pushes Annotations to output queue (assigned to slots 1-4 round-robin)\n\nConfig: provider, model, cache_enabled, cache_path, prompt_template.\n\nMissing from spec:\n- Tool calls to overlay scheduler (currently direct queue push)\n- Runtime prompt editing from admin UI\n- Provider adapters (currently just {provider}:{model} string)\n- Proper prompt template tracking","created_at":"2026-01-17T23:03:57Z"}]}
{"id":"popup-ai-xps","title":"Configuration + CLI (pydantic-settings, typer)","description":"Pydantic-settings config for audio transport, OBS websocket, model/provider settings, STT parameters; include overlay slot mapping defaults popup-scene-1..4 + text source names popup-scene-text1..4, base scene default popup-base-scene, hold_ms default 5000, and SRT ingest settings. Add SettingsStore interface and SQLite-backed persistence for all admin UI editable settings. Include mode flags for modular run modes (ingest/record/transcribe/annotate).","status":"closed","priority":2,"issue_type":"feature","owner":"fcorrao@gmail.com","created_at":"2026-01-17T13:53:25.78443-05:00","created_by":"Frank Corrao","updated_at":"2026-01-17T18:03:33.899709-05:00","closed_at":"2026-01-17T18:03:33.899709-05:00","close_reason":"Implemented pydantic-settings config in src/popup_ai/config.py:\n- AudioIngestConfig: SRT port, latency, sample rate, channels, chunk duration\n- TranscriberConfig: model, chunk length, overlap, language\n- AnnotatorConfig: provider, model, cache settings, prompt template\n- OverlayConfig: OBS host/port/password, scene name, hold duration, max slots\n- PipelineConfig: actor enable flags, headless mode, log level\n- Settings root with env var support (POPUP_ prefix)\n\nCLI uses typer with --headless and --config flags.\n\nMissing: SQLite settings persistence, SettingsStore interface. These tracked in popup-ai-ahl (admin UI).","dependencies":[{"issue_id":"popup-ai-xps","depends_on_id":"popup-ai-e90","type":"blocks","created_at":"2026-01-17T13:54:53.059175-05:00","created_by":"Frank Corrao"},{"issue_id":"popup-ai-xps","depends_on_id":"popup-ai-f33","type":"blocks","created_at":"2026-01-17T15:43:46.319639-05:00","created_by":"Frank Corrao"}]}
{"id":"popup-ai-ye3","title":"Compositor: NDI Output Integration","description":"NDI sender wrapper for outputting composed frames.\n\n**File:** src/popup_ai/ndi_output.py\n\n**Implementation:**\n- Use ndi-python library (pip installable)\n- Create NDI source named 'popup-ai' (configurable)\n- Output BGRA frames at configured fps (30fps default)\n- Handle NDI initialization and cleanup\n\n**Key Code Pattern:**\n```python\nimport NDIlib as ndi\n\n# Initialize\nndi.initialize()\nsend_settings = ndi.SendCreate()\nsend_settings.ndi_name = 'popup-ai'\nndi_send = ndi.send_create(send_settings)\n\n# Send frame\nvideo_frame = ndi.VideoFrameV2()\nvideo_frame.data = bgra_array\nvideo_frame.FourCC = ndi.FOURCC_VIDEO_TYPE_BGRA\nndi.send_send_video_v2(ndi_send, video_frame)\n```\n\n**Considerations:**\n- Verify ndi-python works on macOS, Linux, Windows\n- Fallback: FFmpeg with NDI support if ndi-python fails\n- Clear error message if NDI runtime not installed\n\n**Dependencies:** ndi-python","status":"open","priority":2,"issue_type":"epic","owner":"fcorrao@gmail.com","created_at":"2026-01-19T15:56:32.199266-05:00","created_by":"Frank Corrao","updated_at":"2026-01-19T15:56:32.199266-05:00","labels":["compositor","speculative"]}
